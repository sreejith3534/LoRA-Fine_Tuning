{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "aJ0tN6mCvUvM"
   },
   "outputs": [],
   "source": [
    "# Install the below packages\n",
    "# !pip install transformers datasets peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "yJeenJ6Zvc1L"
   },
   "outputs": [],
   "source": [
    "# Load the Dataset from hugging face\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "dataset = load_dataset(\"PaulAdversarial/all_news_finance_sm_1h2023\")\n",
    "df = dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vNjEbTSuvkY1",
    "outputId": "7e1693cf-6cf6-4dcb-c061-da750e38b7a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "# Preprocessing function to clean the text\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocesses a given text by removing numbers, punctuation, converting to lowercase,\n",
    "    and removing stopwords.\n",
    "    Args:\n",
    "        text (str): The input text to preprocess.\n",
    "    Returns:\n",
    "        str: The preprocessed text with numbers, punctuation, and stopwords removed,\n",
    "             and all words converted to lowercase.\n",
    "    Steps:\n",
    "        1. Removes all digits from the text using regular expressions.\n",
    "        2. Removes punctuation, keeping only alphanumeric characters and spaces.\n",
    "        3. Converts the text to lowercase.\n",
    "        4. Tokenizes the text into individual words.\n",
    "        5. Removes stopwords from the tokenized words.\n",
    "        6. Joins the filtered tokens back into a single string.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "# Apply preprocessing to the text column\n",
    "df['cleaned_text'] = df['title'].apply(preprocess_text)\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=3)\n",
    "# Fit and transform the cleaned text data\n",
    "tfidf_matrix = tfidf.fit_transform(df['cleaned_text'])\n",
    "# Get the feature names (keywords)\n",
    "keywords = tfidf.get_feature_names_out()\n",
    "# Extract top keywords for each row\n",
    "df['key_topics'] = [', '.join([keywords[i] for i in tfidf_matrix[row].indices]) for row in range(tfidf_matrix.shape[0])]\n",
    "# shrinked df with necessary columns\n",
    "df_new = df[['title', 'key_topics', 'description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "t-VtnS8EvoPs"
   },
   "outputs": [],
   "source": [
    "df_without_null = df_new[df[\"key_topics\"] != \"\"].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HtxN0SgfvuOZ"
   },
   "outputs": [],
   "source": [
    "# creating the df back to format which training script accepts\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "\n",
    "dataset_changed = Dataset.from_pandas(df_without_null)\n",
    "dataset_changed_dict = DatasetDict({\n",
    "    'train': dataset_changed\n",
    "})\n",
    "\n",
    "# Split dataset into train and test (90% train, 10% test)\n",
    "dataset_split = dataset_changed_dict['train'].train_test_split(test_size=0.1)\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': dataset_split['train'],\n",
    "    'test': dataset_split['test']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YVEPxxMFvxe-",
    "outputId": "a36f6514-1ce9-4834-8303-363d34a7ac40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Step 1: Check if GPU is available and set device to CUDA or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "eRE4qTGxv0Eg"
   },
   "outputs": [],
   "source": [
    "# Loading the Flan-T5 large model, which will serve as the base for further fine-tuning.\n",
    "\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load the Flan-T5 base model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")\n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-large\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "9xK0CYsuv55Q"
   },
   "outputs": [],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ObPhudSqv_Rt",
    "outputId": "16a8bbf6-eb5a-4880-9554-080cbeb50637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 783150080\n",
      "all model parameters: 783150080\n",
      "percentage of trainable model parameters: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print(print_number_of_trainable_model_parameters(original_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "yZh4TBCPv_Uh"
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    \"\"\"\n",
    "    Preprocesses a batch of examples for input into a model, formatting the input and target\n",
    "    text, and tokenizing them.\n",
    "\n",
    "    Args:\n",
    "        examples (dict): A dictionary containing the input and target text. The keys are:\n",
    "            - 'key_topics': List of input prompts to generate context from.\n",
    "            - 'description': List of target descriptions (labels) to train the model.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing tokenized inputs and labels for the model. The keys are:\n",
    "            - 'input_ids' (list of int): Tokenized inputs.\n",
    "            - 'labels' (list of int): Tokenized target descriptions.\n",
    "    \"\"\"\n",
    "    inputs = examples['key_topics']\n",
    "    targets = examples['description']\n",
    "    inputs = [f\"Generate financial context: {input_text}\" for input_text in inputs]\n",
    "    model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding=\"max_length\")\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=512, truncation=True, padding=\"max_length\")\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "b27f9d4c11f34fb3985ddc6a5ce524d3",
      "90356b2da87a4af3a127fec0bc30d5da",
      "cbc9df164cb74b98952c51f3b4d2b388",
      "d4935edc990f43449fc101dc62797636",
      "669cfd191ee5420aaafb1d225cbb00fd",
      "6a16b1ccfc8247f99457c69c8bd9b2a8",
      "ccdaba3afa6240a4b0864831f79a0129",
      "5aec45009ab94a4bb366ab8372249324",
      "a3bcc70195e74e2ea0b7a1ccc87df8e2",
      "46b5b37f6faf4ff3b11f6dc6eebd8275",
      "b4dbc57d2e5240fdadade01cb7e56393",
      "20e7b038e2c7468d99b18e9bd403d8d2",
      "a624c94d38d548ca810e5e3c4547c4bc",
      "98087031db4949f2a9a3b9c9f50af804",
      "509d49de3af846a39a570461e113ef02",
      "d5691af820914e768ffccbe407418289",
      "a64a8c104bad454cb3aa14f892980900",
      "6f10e0385a574f9d96032c60a98d0430",
      "b46323b741104330a24ee3b238c7dbe6",
      "1e537516d16244e0ac9ea108916b732d",
      "45e8758c2bec482f9e4f2bdd0e93d894",
      "7a02619028cf49fa8b58be5771dd5d88"
     ]
    },
    "id": "WXWT6a7ev_W5",
    "outputId": "05fe2678-f81e-4695-a54d-ebd67f59b204"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b27f9d4c11f34fb3985ddc6a5ce524d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1764 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:4016: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e7b038e2c7468d99b18e9bd403d8d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/196 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasaet = dataset_dict.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "emkQt-xEv_Zh"
   },
   "outputs": [],
   "source": [
    "# Setting up the hyper-parameter combination for LoRA\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32, # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(original_model,\n",
    "                            lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4AHAsFOHv_b3",
    "outputId": "2fa1f19d-fb54-4b58-aedc-a6099404f446"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 9437184\n",
      "all model parameters: 792587264\n",
      "percentage of trainable model parameters: 1.19%\n"
     ]
    }
   ],
   "source": [
    "print(print_number_of_trainable_model_parameters(peft_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v5wm99iBv_ea",
    "outputId": "ed4db13b-c050-4593-8b90-6033f65669d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "## Training args\n",
    "\n",
    "import time\n",
    "from transformers import TrainingArguments, Trainer\n",
    "output_dir = f'./peft-dialogue-summary-training-{str(int(time.time()))}'\n",
    "\n",
    "peft_training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    auto_find_batch_size=True,\n",
    "    learning_rate=1e-3, # Higher learning rate than full fine-tuning.\n",
    "    num_train_epochs=100,\n",
    "    logging_steps=1,\n",
    "    max_steps=10\n",
    ")\n",
    "\n",
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset=tokenized_datasaet[\"train\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "aZL8mjrXxjUF",
    "outputId": "caf2c3da-e8ed-4673-fb19-e9cb10f87500"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:05, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>41.299000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>42.492500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>37.542600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>32.085800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>37.153400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>18.964800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>28.282500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>29.521600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>19.871800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>25.714500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10, training_loss=31.292854690551756, metrics={'train_runtime': 6.1561, 'train_samples_per_second': 1.624, 'train_steps_per_second': 1.624, 'total_flos': 5834397450240.0, 'train_loss': 31.292854690551756, 'epoch': 0.005668934240362812})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPglFJhb2H8U"
   },
   "source": [
    "### Save your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8uZa9_JJv_j7",
    "outputId": "4b2090c4-79ec-44d1-92af-f8112e76852a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./peft-results-local_1/tokenizer_config.json',\n",
       " './peft-results-local_1/special_tokens_map.json',\n",
       " './peft-results-local_1/spiece.model',\n",
       " './peft-results-local_1/added_tokens.json',\n",
       " './peft-results-local_1/tokenizer.json')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model_path=\"./peft-results-local_1\"\n",
    "\n",
    "peft_trainer.model.save_pretrained(peft_model_path)\n",
    "tokenizer.save_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDmTpOqL11QS"
   },
   "source": [
    "### Loading base model and taking the fine tuned model using peft (1.19 percent were only trainable params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "-boh_qfRxwJF"
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "# peft_model_base = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\", torch_dtype=torch.bfloat16)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "# Load the Flan-T5 base model and tokenizer\n",
    "# model_name = \"google/flan-t5-large\"\n",
    "# tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "# peft_model_base = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")\n",
    "peft_model_base = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-large\").to(device)\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(peft_model_base,\n",
    "                                       '/content/peft-results-local_1',\n",
    "                                       torch_dtype=torch.bfloat16,\n",
    "                                       is_trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "W17xE86cyKRx"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, input_text, tokenizer, max_length=512):\n",
    "    \"\"\"\n",
    "    Generates text based on a given input prompt using a pre-trained language model and tokenizer.\n",
    "\n",
    "    Args:\n",
    "        model (transformers.PreTrainedModel): The pre-trained language model to generate text with.\n",
    "        input_text (str): The input prompt text to generate context from.\n",
    "        tokenizer (transformers.PreTrainedTokenizer): The tokenizer used to preprocess the input text for the model.\n",
    "        max_length : The maximum length of the generated text. Defaults to 512.\n",
    "    Returns:\n",
    "        str: The generated text, decoded from the model's output without special tokens.\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = model.to(device)\n",
    "    inputs = tokenizer(f\"Generate financial context: {input_text}\", return_tensors=\"pt\").to(device)\n",
    "    output_sequences = model.generate(input_ids=inputs['input_ids'], max_length=max_length)\n",
    "    generated_text = tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DTSgVLX1sRM"
   },
   "source": [
    "## Sample Output tesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UI_aue79yRh5",
    "outputId": "e465a877-b8a0-4da7-eb54-79a02e773973"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Output:\n",
      " BTC price down\n",
      "\n",
      "Fine-Tuned Model Output:\n",
      " Bitcoin price down on Monday, after a strong rally on the exchange.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"BTC price down\"\n",
    "# input_text = \"bitcoin\"\n",
    "\n",
    "# Generate text from the base model\n",
    "base_output = generate_text(original_model, input_text, tokenizer)\n",
    "print(\"Base Model Output:\\n\", base_output)\n",
    "\n",
    "# Generate text from the fine-tuned model\n",
    "fine_tuned_output = generate_text(peft_model, input_text, tokenizer)\n",
    "print(\"\\nFine-Tuned Model Output:\\n\", fine_tuned_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kHSeOZ0_yRjw",
    "outputId": "8a002e7c-6ec1-4e7f-bf96-aab6cb92fedd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Output:\n",
      " During the first half of the year, the oil and gas sector saw a net increase in production, averaging a total of 1.2 million barrels per day.\n",
      "\n",
      "Fine-Tuned Model Output:\n",
      " Oil prices have been falling for the past several years, but the recent drop has been attributed to the continuing weakness of the global economy.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"oil\"\n",
    "\n",
    "# Generate text from the base model\n",
    "base_output = generate_text(original_model, input_text, tokenizer)\n",
    "print(\"Base Model Output:\\n\", base_output)\n",
    "\n",
    "# Generate text from the fine-tuned model\n",
    "fine_tuned_output = generate_text(peft_model, input_text, tokenizer)\n",
    "print(\"\\nFine-Tuned Model Output:\\n\", fine_tuned_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cwk1lwEzyRmV",
    "outputId": "5e08e42d-9ea0-4cd6-eaa5-408b3dc117d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Output:\n",
      " Bitcoin is a crypto-currency that was created in 2014 by the Bitcoin network.\n",
      "\n",
      "Fine-Tuned Model Output:\n",
      " Bitcoin is a crypto currency that was created in 2009 by a group of hackers who hacked into the Bitcoin network.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"bitcoin\"\n",
    "\n",
    "# Generate text from the base model\n",
    "base_output = generate_text(original_model, input_text, tokenizer)\n",
    "print(\"Base Model Output:\\n\", base_output)\n",
    "\n",
    "# Generate text from the fine-tuned model\n",
    "fine_tuned_output = generate_text(peft_model, input_text, tokenizer)\n",
    "print(\"\\nFine-Tuned Model Output:\\n\", fine_tuned_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g2hOd7sMyRoy",
    "outputId": "d4f685cb-95b1-4b51-8088-d33b57b777bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Output:\n",
      " price of oil is the price of the oil.\n",
      "\n",
      "Fine-Tuned Model Output:\n",
      " During the first half of the year, the company reported a net profit of $2.2 billion, compared to a net loss of $2.2 billion in the first half of the year.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"price\"\n",
    "\n",
    "# Generate text from the base model\n",
    "base_output = generate_text(original_model, input_text, tokenizer)\n",
    "print(\"Base Model Output:\\n\", base_output)\n",
    "\n",
    "# Generate text from the fine-tuned model\n",
    "fine_tuned_output = generate_text(peft_model, input_text, tokenizer)\n",
    "print(\"\\nFine-Tuned Model Output:\\n\", fine_tuned_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CJBkDEnRyRrR",
    "outputId": "1f952553-f803-40d7-e4bb-ec0b01c4e17d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Output:\n",
      " The ECB has lowered its monetary policy to a 2% to 2% rate.\n",
      "\n",
      "Fine-Tuned Model Output:\n",
      " Inflation is the increase in the price of goods and services.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"inflation\"\n",
    "\n",
    "# Generate text from the base model\n",
    "base_output = generate_text(original_model, input_text, tokenizer)\n",
    "print(\"Base Model Output:\\n\", base_output)\n",
    "\n",
    "# Generate text from the fine-tuned model\n",
    "fine_tuned_output = generate_text(peft_model, input_text, tokenizer)\n",
    "print(\"\\nFine-Tuned Model Output:\\n\", fine_tuned_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4gxxdnZhyRt0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ieSd5JvyRxP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1e537516d16244e0ac9ea108916b732d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "20e7b038e2c7468d99b18e9bd403d8d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a624c94d38d548ca810e5e3c4547c4bc",
       "IPY_MODEL_98087031db4949f2a9a3b9c9f50af804",
       "IPY_MODEL_509d49de3af846a39a570461e113ef02"
      ],
      "layout": "IPY_MODEL_d5691af820914e768ffccbe407418289"
     }
    },
    "45e8758c2bec482f9e4f2bdd0e93d894": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46b5b37f6faf4ff3b11f6dc6eebd8275": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "509d49de3af846a39a570461e113ef02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45e8758c2bec482f9e4f2bdd0e93d894",
      "placeholder": "​",
      "style": "IPY_MODEL_7a02619028cf49fa8b58be5771dd5d88",
      "value": " 196/196 [00:00&lt;00:00, 1896.37 examples/s]"
     }
    },
    "5aec45009ab94a4bb366ab8372249324": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "669cfd191ee5420aaafb1d225cbb00fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a16b1ccfc8247f99457c69c8bd9b2a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f10e0385a574f9d96032c60a98d0430": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a02619028cf49fa8b58be5771dd5d88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "90356b2da87a4af3a127fec0bc30d5da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6a16b1ccfc8247f99457c69c8bd9b2a8",
      "placeholder": "​",
      "style": "IPY_MODEL_ccdaba3afa6240a4b0864831f79a0129",
      "value": "Map: 100%"
     }
    },
    "98087031db4949f2a9a3b9c9f50af804": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b46323b741104330a24ee3b238c7dbe6",
      "max": 196,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1e537516d16244e0ac9ea108916b732d",
      "value": 196
     }
    },
    "a3bcc70195e74e2ea0b7a1ccc87df8e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a624c94d38d548ca810e5e3c4547c4bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a64a8c104bad454cb3aa14f892980900",
      "placeholder": "​",
      "style": "IPY_MODEL_6f10e0385a574f9d96032c60a98d0430",
      "value": "Map: 100%"
     }
    },
    "a64a8c104bad454cb3aa14f892980900": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b27f9d4c11f34fb3985ddc6a5ce524d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_90356b2da87a4af3a127fec0bc30d5da",
       "IPY_MODEL_cbc9df164cb74b98952c51f3b4d2b388",
       "IPY_MODEL_d4935edc990f43449fc101dc62797636"
      ],
      "layout": "IPY_MODEL_669cfd191ee5420aaafb1d225cbb00fd"
     }
    },
    "b46323b741104330a24ee3b238c7dbe6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4dbc57d2e5240fdadade01cb7e56393": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cbc9df164cb74b98952c51f3b4d2b388": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5aec45009ab94a4bb366ab8372249324",
      "max": 1764,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a3bcc70195e74e2ea0b7a1ccc87df8e2",
      "value": 1764
     }
    },
    "ccdaba3afa6240a4b0864831f79a0129": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d4935edc990f43449fc101dc62797636": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46b5b37f6faf4ff3b11f6dc6eebd8275",
      "placeholder": "​",
      "style": "IPY_MODEL_b4dbc57d2e5240fdadade01cb7e56393",
      "value": " 1764/1764 [00:00&lt;00:00, 2717.67 examples/s]"
     }
    },
    "d5691af820914e768ffccbe407418289": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
